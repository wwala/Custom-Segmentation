{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> $\\color{darkblue}{\\text{Customer Personality Analysis}}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center> $\\color{darkblue}{\\text{W. Touhami - Dec 2021}}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem Statement__\n",
    "\n",
    "Customer Personality Analysis is a detailed analysis of a company’s ideal customers. It helps a business to better understand its customers and makes it easier for them to modify products according to the specific needs, behaviors and concerns of different types of customers.\n",
    "\n",
    "Customer personality analysis helps a business to modify its product based on its target customers from different types of customer segments. For example, instead of spending money to market a new product to every customer in the company’s database, a company can analyze which customer segment is most likely to buy the product and then market the product only on that particular segment.\n",
    "\n",
    "__Target__\n",
    "\n",
    "Need to perform clustering to summarize customer segments.\n",
    "\n",
    "__Data__\n",
    "We use a dataset from Kaggle.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Why is customer segmentation important__\n",
    "\n",
    "All types od segmentation help the compagny to spend money affeciently. The segmentation helps to decide which marketing strategies deserve different allocations of ressources.\n",
    "\n",
    "__Improving products__\n",
    "\n",
    "Customer segmentation helps the compagny to improve their products through a better understanding of who uses them.\n",
    "\n",
    "Customer segmentation ca enable te craft more engaging message. Allowing customised messages to each segment brings about higher quality enthusiasm for your brand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{darkblue}{\\text{Table of content}}$\n",
    "\n",
    "1. Data loading\n",
    "1. Data Analysis\n",
    "1. Data cleaning\n",
    "1. Data Preprocessing\n",
    "1. Clustering\n",
    "1. Discussion\n",
    "1. General conclusion and recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{darkblue}{\\text{Import Libraries}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.5.0-py2.py3-none-any.whl (26.5 MB)\n",
      "     |████████████████████████████████| 26.5 MB 1.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six in /Users/wala/opt/anaconda3/lib/python3.7/site-packages (from plotly) (1.15.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Using cached tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.5.0 tenacity-8.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wala/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-514ac1daf326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  $\\color{darkblue}{\\text{1- Data loading}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of 2240 customers described with 29 features\n",
    "\n",
    "__Features__\n",
    "\n",
    "People\n",
    "<ul>\n",
    "<li> ID: Customer's unique identifier</li>\n",
    "<li> Year_Birth: Customer's birth year</li>\n",
    "<li> Education: Customer's education level</li>\n",
    "<li> Marital_Status: Customer's marital status</li>\n",
    "<li> Income: Customer's yearly household income</li>\n",
    "<li> Kidhome: Number of children in customer's household</li>\n",
    "<li> Teenhome: Number of teenagers in customer's household</li>\n",
    "<li> Dt_Customer: Date of customer's enrollment with the company</li>\n",
    "<li> Recency: Number of days since customer's last purchase</li>\n",
    "<li>Complain: 1 if customer complained in the last 2 years, 0 otherwise</li>\n",
    " </ul>\n",
    "Products\n",
    "<ul>\n",
    "<li>MntWines: Amount spent on wine in last 2 years</li>\n",
    "<li>MntFruits: Amount spent on fruits in last 2 years</li>\n",
    "<li>MntMeatProducts: Amount spent on meat in last 2 years</li>\n",
    "<li>MntFishProducts: Amount spent on fish in last 2 years</li>\n",
    "<li>MntSweetProducts: Amount spent on sweets in last 2 years</li>\n",
    "<li>MntGoldProds: Amount spent on gold in last 2 years</li>\n",
    " </ul>\n",
    "Promotion\n",
    "<ul>\n",
    "<li>NumDealsPurchases: Number of purchases made with a discount</li>\n",
    "<li>AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise</li>\n",
    "<li>AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise</li>\n",
    "<li>AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise</li>\n",
    "<li>AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise</li>\n",
    "<li>AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise</li>\n",
    "<li>Response: 1 if customer accepted the offer in the last campaign, 0 otherwise</li>\n",
    " </ul>\n",
    "Place\n",
    "<ul>\n",
    "<li>NumWebPurchases: Number of purchases made through the company’s web site</li>\n",
    "<li>NumCatalogPurchases: Number of purchases made using a catalogue</li>\n",
    "<li>NumStorePurchases: Number of purchases made directly in stores</li>\n",
    "<li>NumWebVisitsMonth: Number of visits to company’s web site in the last month</li>\n",
    " </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('marketing_campaign.csv',index_col=False,sep=\"\\t\")\n",
    "print(f'Dataset with {df.shape[0]} entries and {df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{darkblue}{\\text{2- Data analysis}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let examine data\n",
    "#pd.set_option('display.max_columns', None)\n",
    "dataname = 'Marketing Compaign'\n",
    "\n",
    "print(f'Let have a look to dataset {dataname}:\\n')\n",
    "display(df.head())\n",
    "\n",
    "  \n",
    "print('Some stats:')\n",
    "display(df.describe())\n",
    " \n",
    "\n",
    "# Duplicates rows\n",
    "duplicates = df.duplicated().sum()\n",
    "if duplicates == 0:\n",
    "    print(\"\\n\")\n",
    "    print('There are no duplicated entries.')\n",
    "else:\n",
    "    print(\"\\n\")\n",
    "    print(f'There are {duplicates} duplicates.')\n",
    "\n",
    "   \n",
    "# Missing values\n",
    "data_missing = pd.DataFrame(df.isnull().sum())\n",
    "if data_missing[0].sum() > 0:\n",
    "    print('\\n Missing values')\n",
    "    data_missing.plot(kind='bar')\n",
    "    plt.grid()\n",
    "    plt.title('Missing values');\n",
    "else:\n",
    "    print(f'There are no missing values in \"{data_name}\".')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__ \n",
    "\n",
    "1. The dataset contains 2240 customers described with 29 features (including customer's ID)\n",
    "\n",
    "1. Columns 'Z_CostContact','Z_Revenue' with equal values, so no relevant information, we will drop these 2 columns\n",
    "\n",
    "1. No duplicated values\n",
    "\n",
    "1. There some missing values (24) in column 'Income'\n",
    "\n",
    "1. There some outliers in column 'Income' (for example 666666 is outlier) and in column 'year_birth', the value 1893 seems outiers too\n",
    "1. Dt_Customer that indicates the date a customer joined the database is not parsed as DateTime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{darkblue}{\\text{3- Data cleaning}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataframe\n",
    "data = df.copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing data\n",
    "data = data.dropna()\n",
    "print(\"The total number of data-points after removing the rows with missing values are:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Dt_Customer to DateTime \n",
    "data[\"Dt_Customer\"] = pd.to_datetime(data[\"Dt_Customer\"])\n",
    "type(data[\"Dt_Customer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical features\n",
    "print(\"Total categories in the feature Marital_Status:\\n\", data[\"Marital_Status\"].value_counts(), \"\\n\")\n",
    "print(\"Total categories in the feature Education:\\n\", data[\"Education\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Some modifications__\n",
    "\n",
    "1. Extract the \"Age\" of a customer by the \"Year_Birth\" indicating the birth year of the respective person. \n",
    "1. Create a feature \"Spent\" indicating the total amount spent by the customer in various categories. \n",
    "1. Modify feature \"Marital_Status\": <ol>\n",
    "                                    <li> Single/Absurd/Divorced/widow/Alone/Yolo --> Single:1 \n",
    "                                    <li> Married/together --> Married:2 \n",
    "                                    </ol>\n",
    "1. Create a feature \"Children\" to indicate total children = kids and teenagers.\n",
    "1. Create a feature \"FamilySize\" to indicate total nb of persons \n",
    "\n",
    "1. Simplify feature \"Education\" :<ol>\n",
    "                                 <li> Basic/2nCycle --> Undergraduate \n",
    "                                 <li> Graduation --> Graduate \n",
    "                                 <li> Master/PhD --> Postgraduate \n",
    "                                 </ol>\n",
    "1. Create feautre \"Enrollment\": Modify date of enrollment 'Dt_customer' to duration of registration \n",
    "1. Drop the outliers examples where Age > 100 and Income> 600000 \n",
    "1. Drop not necessary columns: 'Z_CostContact','Z_Revenue', 'Year_Birth', 'DT_Customer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extract Age\n",
    "data['Age'] = 2021 - data['Year_Birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create 'Spent' feature\n",
    "data['Spent'] = data['MntFishProducts'] + data['MntFruits'] + data['MntGoldProds'] + data['MntMeatProducts'] + data['MntSweetProducts'] + data['MntWines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Modify 'Marital_Status' feature\n",
    "data['Marital_Status'].replace({'Married':2,'Together':2,'Alone':1,'YOLO':1,'Single':1,'Absurd':1,'Widow':1,'Divorced':1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Add feature children\n",
    "data['Children'] = data['Kidhome'] + data['Teenhome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Add Feature FamilySize\n",
    "data['FamilySize'] = data['Children'] + data['Marital_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Modify 'Education' feature and replace the column by \"EducationGrad\"\n",
    "df['Education'].replace({'Basic':'Undergraduate','2n Cycle':'Undergraduate','Graduation':'Graduate','Master':'Postgraduate','PhD':'Postgraduate'},inplace=True)\n",
    "data['EducationGrad'] = df['Education']\n",
    "data['EducationGrad'].replace({'Undergraduate':0,'Graduate':1,'Postgraduate':2},inplace=True)\n",
    "data['EducationGrad'] = pd.to_numeric(data['EducationGrad'])\n",
    "\n",
    "data.drop(columns=['Education'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Modify date of enrollment 'Dt_customer' \n",
    "#date_now = datetime.datetime.now().date()\n",
    "years = []\n",
    "for i in data[\"Dt_Customer\"]:\n",
    "    i = i.year\n",
    "    years.append(2021 - i)\n",
    " \n",
    "data['Enrollment'] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. drop outliers examples\n",
    "indexNames = data[ data['Age'] > 100 ].index\n",
    "data.drop(indexNames , inplace=True)\n",
    "data.drop(data[ data['Income'] > 600000 ].index , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. drop non necessary columns\n",
    "data.drop(columns=['Z_CostContact','Z_Revenue','Year_Birth', 'Dt_Customer'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The cleaned dataset:\\n')\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some graphs to illustrate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.subplot(4,3,1)\n",
    "plt.scatter(data['Income'],data['Spent'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Spent')\n",
    "\n",
    "plt.subplot(4,3,2)\n",
    "plt.scatter(data['Age'],data['Spent'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Spent')\n",
    "plt.subplot(4,3,3)\n",
    "plt.scatter(data['Marital_Status'],data['Spent'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('Marital_Status')\n",
    "plt.ylabel('Spent')\n",
    "plt.subplot(4,3,4)\n",
    "plt.scatter(data['Income'],data['MntWines'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('MntWines')\n",
    "plt.subplot(4,3,5)\n",
    "plt.scatter(data['Income'],data['MntFruits'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('MntFruits')\n",
    "plt.subplot(4,3,6)\n",
    "plt.scatter(data['Income'],data['MntMeatProducts'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('MntMeatProducts')\n",
    "plt.subplot(4,3,7)\n",
    "plt.scatter(data['Income'],data['MntFishProducts'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('MntFishProducts')\n",
    "plt.subplot(4,3,8)\n",
    "plt.scatter(data['Income'],data['MntSweetProducts'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('MntSweetProducts')\n",
    "plt.subplot(4,3,9)\n",
    "plt.scatter(data['FamilySize'],data['Spent'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('FamilySize')\n",
    "plt.ylabel('Spent')\n",
    "plt.subplot(4,3,10)\n",
    "plt.scatter(data['NumDealsPurchases'],data['Spent'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('NumDealsPurchases')\n",
    "plt.ylabel('Spent')\n",
    "plt.subplot(4,3,11)\n",
    "plt.scatter(data['NumDealsPurchases'],data['Income'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('NumDealsPurchases')\n",
    "plt.ylabel('Income')\n",
    "plt.subplot(4,3,12)\n",
    "plt.scatter(data['NumDealsPurchases'],data['FamilySize'],c='blue',alpha=0.5,lw=.2)\n",
    "plt.xlabel('NumDealsPurchases')\n",
    "plt.ylabel('FamilySize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features\n",
    "plt.figure(figsize=(16,9))\n",
    "ax = sns.heatmap(data.corr(),annot = True,cmap = 'YlGnBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_feat(dataset, columns_list, rows, cols, suptitle, size=(16,8), y=0.5):\n",
    "    fig, axs = plt.subplots(rows, cols,figsize=size)\n",
    "    fig.suptitle(suptitle,y=y, size=16)\n",
    "    axs = axs.flatten() \n",
    "    for i, data in enumerate(columns_list):\n",
    "        mean, median = dataset[data].mean(), dataset[data].median()\n",
    "        graph = sns.histplot(dataset[data], ax=axs[i])\n",
    "        graph.axvline(mean, c='red',label='mean')\n",
    "        graph.axvline(median, c='green',label='median')\n",
    "        graph.legend()\n",
    "        #axs[i].set_title(data)\n",
    "\n",
    "col_list = ['Income', 'Kidhome','MntWines', 'MntFruits','MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "            'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases','NumCatalogPurchases', 'NumStorePurchases',\n",
    "             'NumWebVisitsMonth']     \n",
    "dist_feat(dataset=data, columns_list=col_list, \n",
    "            rows=5, cols=3, suptitle='Distibution for each variable', size=(18,28), y=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\color{blue}{\\text{Observations}}$ \n",
    "\n",
    "1. Feature 'Income' has mean and median almost similar unlike the others features\n",
    "2. Most features has Right skewed distribution except features 'NumStorePurchases' and 'NumWebVisitsMonth': customers prefer buying on web/store than through catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cat_list = ['Education', 'Marital_Status']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2,figsize=(14,8))\n",
    "fig.suptitle('Barchar for education types and marital status',size=16)\n",
    "#fig.tight_layout(pad=6.0)\n",
    "axs = axs.flatten() \n",
    "    \n",
    "for i, col in enumerate(col_cat_list):\n",
    "    df_c = df.groupby(col).count().reset_index()\n",
    "    pal = sns.color_palette(\"Greens_d\", len(df_c))\n",
    "    rank = df_c['ID'].argsort().argsort() \n",
    "        \n",
    "    g=sns.barplot(df_c[col], df_c['ID'], ax=axs[i], palette=np.array(pal[::-1])[rank])\n",
    "    plt.legend()\n",
    "    for index, row in df_c.iterrows():\n",
    "        g.text(row.name,row.ID, round(row.ID,2), color='black', ha=\"center\")\n",
    "            \n",
    "   \n",
    "    axs[i].tick_params(axis='y')\n",
    "    df_c = df.groupby(col)['Income'].mean().reset_index()\n",
    "    axs[i] = axs[i].twinx()\n",
    "    sns.lineplot(df_c[col], df_c['Income'], ax=axs[i], color='red', label='mean income')\n",
    "    axs[i].tick_params(axis='y')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\color{blue}{\\text{Observations}}$\n",
    "\n",
    "1. From the plot above we can see that customers with PostGraduate degree (Master and PhD) have the highest income in comparison to others education types. Clients with 'UnderGraduate' education don't earn a lot in average.\n",
    "\n",
    "2. Marital status: customers with marital status \"Absurd\" has the highest income, should be investigated carefully. The lowest income reffers to alone and YOLO people: such clients can be too young or too old and don't earn lots money.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{darkblue}{\\text{4- Data preprocessing}}$\n",
    "\n",
    "1. Data normalization\n",
    "1. Reducing features dimensions using PCA method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "obje_ss=StandardScaler()\n",
    "\n",
    "X_scaled=obje_ss.fit(data)\n",
    "scaled_data = pd.DataFrame(obje_ss.transform(data),columns= data.columns )\n",
    "print(\"All features are now scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dimensions Features reducing to 3/4: PCA\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "pca.fit(scaled_data)\n",
    "df_pca = pd.DataFrame(pca.transform(scaled_data), columns=([\"f1\",\"f2\", \"f3\",\"f4\"]))\n",
    "df_pca.describe().T\n",
    "print('Results after PCA method')\n",
    "print(df_pca.head())\n",
    "\n",
    "\n",
    "# Ploting result data with the use of scatterplot. plotly\n",
    "x =df_pca[\"f1\"]\n",
    "y =df_pca[\"f2\"]\n",
    "z =df_pca[\"f3\"]\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x,y=y,z=z,mode='markers',\n",
    "    marker=dict(size=6,color=x,opacity=0.8))])\n",
    "\n",
    "# tight layout\n",
    "fig.update_layout( title={'text': \"3D scatterplot of size-reduced data\",'y':0.9,\n",
    "        'x':0.5,'xanchor': 'center','yanchor': 'top'},\n",
    "                  margin=dict(l=200, r=220, b=0, t=0))\n",
    "fig.show()\n",
    "fig.update(layout_coloraxis_showscale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{darkblue}{\\text{5- Clustering}}$\n",
    "\n",
    "Clustering is an __unsupervised learning__ problem. It is used as a technique for groups segmentation.\n",
    "\n",
    "There are many clustering algorithms:  Kmeans, Agglomerative Clustering,DBscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Elbow method__:in clustering, it means one should choose a number of clusters so that adding another cluster doesn't give much better modeling of the data.\n",
    "\n",
    "The __KElbowVisualizer__ implements the “elbow” method to help data scientists select the optimal number of clusters by fitting the model with a range of values for 𝐾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import sklearn.cluster as cluster\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.metrics import silhouette_score \n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer\n",
    "model = cluster.KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=10)\n",
    "\n",
    "# Fit the data to the visualizer\n",
    "visualizer.fit(df_pca) \n",
    "\n",
    "# Finalize and render the figure\n",
    "visualizer.show()       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwds = {'alpha' : 0.25, 's' : 50, 'linewidths':0}\n",
    "clusters_series = []\n",
    "score_silh = []\n",
    "score_hara = []\n",
    "score_bould =[]\n",
    "\n",
    "algorithms = [cluster.KMeans,cluster.AgglomerativeClustering,cluster.DBSCAN]\n",
    "args = [ (), (), ()]\n",
    "kwds = [{'n_clusters':4}, {'n_clusters':4, 'linkage':'ward'}, {'eps':0.605}]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16, 10), sharex=True, sharey=True)\n",
    "#axs = axs.flatten()\n",
    "\n",
    "for j, i in zip(range(len(algorithms)),axs.ravel()):\n",
    "        algorithm = algorithms[j]\n",
    "        start_time = time.time()\n",
    "        labels = algorithm(*args[j], **kwds[j]).fit_predict(df_pca)\n",
    "        end_time = time.time()\n",
    "        clusters_series.append(labels)\n",
    "        #plotting\n",
    "        palette = sns.color_palette('deep', np.unique(labels).max() + 1)\n",
    "        colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\n",
    "        if j < len(algorithms):       \n",
    "                i.scatter(df_pca.iloc[:,0], df_pca.iloc[:,1],c=colors,  **plot_kwds)\n",
    "                i.set_title('Clusters found by {}'.format(str(algorithm.__name__)), fontsize=14)\n",
    "                i.text(4, 6, 'Time: {:.2f} s'.format(end_time - start_time), fontsize=10)\n",
    "        # Calculate cluster validation metrics  \n",
    "        score_s = silhouette_score(df_pca, labels, metric='euclidean')\n",
    "        score_silh.append(score_s)\n",
    "        score_c = calinski_harabasz_score(df_pca, labels)\n",
    "        score_hara.append(score_c)\n",
    "        score_d = davies_bouldin_score(df_pca, labels)\n",
    "        score_bould.append(score_d)\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "print (\"KMeans Algo:\")\n",
    "print('Silhouette Score: %.4f' % score_silh[0])\n",
    "print('Calinski Harabasz Score: %.4f' % score_hara[0])\n",
    "print('Davies Bouldin Score: %.4f' % score_bould[0])  \n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "print (\"Agglomerative Algo:\")\n",
    "print('Silhouette Score: %.4f' % score_silh[1])\n",
    "print('Calinski Harabasz Score: %.4f' % score_hara[1])\n",
    "print('Davies Bouldin Score: %.4f' % score_bould[1])  \n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "print (\"DBSCAN Algo:\")\n",
    "print('Silhouette Score: %.4f' % score_silh[2])\n",
    "print('Calinski Harabasz Score: %.4f' % score_hara[2])\n",
    "print('Davies Bouldin Score: %.4f' % score_bould[2])  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df_pca[\"clusters_affinity\"], df_pca[\"clusters_spectral\"] =  clusters_series[1],clusters_series[3]\n",
    "df_pca[\"clusters_kmeans\"], df_pca[\"clusters_agglom\"],df_pca[\"clusters_dbscan\"] =   clusters_series[0],clusters_series[1],clusters_series[2]\n",
    "data[\"clusters_kmeans\"], data[\"clusters_agglom\"],data[\"clusters_dbscan\"] =   clusters_series[0],clusters_series[1],clusters_series[2]\n",
    "#df_filtered[\"clusters_affinity\"], df_filtered[\"clusters_spectral\"] =  clusters_series[1],clusters_series[3]\n",
    "#df_filtered[\"clusters_kmeans\"], df_filtered[\"clusters_agglom\"] =   clusters_series[2],clusters_series[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that __K-means__ outperforms others clustering algorithms based on all cluster validation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{darkblue}{\\text{6- Discussion}}$\n",
    "\n",
    "Let focus on KMeans and analyse the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=plt.figure(figsize=(16,8))\n",
    "cmap=['cyan','pink','green','orange']\n",
    "\n",
    "\n",
    "sns.scatterplot(data = data,x=data[\"Spent\"], y=data[\"Income\"],hue=data['clusters_kmeans'], palette='viridis_r')\n",
    "plt.title(\"Kmeans Clustering\")\n",
    "plt.legend()\n",
    "plt.suptitle(\"Cluster's Profile Based On Income And Spending\", y=0.95);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{darkblue}{\\text{Clusters analysis}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = data['clusters_kmeans'].value_counts()\n",
    "ct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pl = sns.countplot(x=data[\"clusters_kmeans\"],palette='viridis_r')\n",
    "pl.set_title(\"Distribution Of The Clusters\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "ax = plt.subplot(2,2,1)\n",
    "sns.countplot(x=data['Marital_Status'],hue=data['clusters_kmeans'],palette=\"viridis_r\")\n",
    "pl.set_title(\"Distribution Of Marital Status\")\n",
    "ax = plt.subplot(2,2,2)\n",
    "sns.countplot(x=data['FamilySize'],hue=data['clusters_kmeans'],palette=\"viridis_r\")\n",
    "pl.set_title(\"Distribution Of Family Size\")\n",
    "ax = plt.subplot(2,2,3)\n",
    "sns.countplot(x=data['Kidhome'],hue=data['clusters_kmeans'],palette=\"viridis_r\")\n",
    "pl.set_title(\"Distribution Of Kids\")\n",
    "ax = plt.subplot(2,2,4)\n",
    "sns.countplot(x=data['Teenhome'],hue=data['clusters_kmeans'],palette=\"viridis_r\")\n",
    "pl.set_title(\"Distribution Of Teengers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Observations:__\n",
    "1. Middle income, Middle/high spent\n",
    "1. Few offers are accepted\n",
    "1. Web and store purchases are used less than catalog purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{darkblue}{\\text{Clusters interpretation}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['ID','clusters_agglom','clusters_dbscan'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'clusters_kmeans':'Cluster'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters interpretation\n",
    "sns.set(style=\"ticks\",rc={\"axes.spines.left\": True,'axes.facecolor':'black', 'figure.facecolor':'black', 'axes.grid' : False, 'font.family': 'Dejavu Sans'})\n",
    "\n",
    "\n",
    "for i in data:\n",
    "    g = sns.FacetGrid(data, col = \"Cluster\", hue = \"Cluster\", palette = \"Set2\")\n",
    "    g.map(plt.hist, i, bins=10, ec=\"k\") \n",
    "    mean, median = data[i].mean(),data[i].median()\n",
    "    g.refline(x=mean, color='red')\n",
    "    g.set_xticklabels(rotation=30, color = 'white')\n",
    "    g.set_yticklabels(color = 'white')\n",
    "    g.set_xlabels(size=15, color = 'white')\n",
    "    g.set_titles(size=15, color = '#FFC300', fontweight=\"bold\")\n",
    "    g.fig.set_figheight(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Cluster 0</th>\n",
    "      <th>Cluster 1</th>\n",
    "      <th>Cluster 2</th>\n",
    "      <th>Cluster 3</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Low Income, less than overall mean</td>\n",
    "      <td>Middle Income, the cluster's mean is > than the dataset's mean</td>\n",
    "      <td>Middle Income</td>\n",
    "      <td>High Income, largement supérieur than the dataset's mean</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Low spent, less than mean of dataset's spent </td>\n",
    "      <td>Middle spent the cluster's mean is > than the dataset's mean </td>\n",
    "      <td>Middle spent</td>\n",
    "      <td>High spent, largement supérieur than the dataset's mean</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Plutot jeune </td>\n",
    "      <td>Uniformément distribué </td>\n",
    "      <td>plutot agé, moy > dataset's mean</td>\n",
    "      <td>Uniformément distribué </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Majoity Graduated and Post graduated </td>\n",
    "      <td>Majoity Graduated </td>\n",
    "      <td>Majoity Post graduated</td>\n",
    "      <td>Majoity Graduated and Post graduated </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Most web/store purchases</td>\n",
    "      <td>Most store purchases</td>\n",
    "      <td>Most web/store purchases</td>\n",
    "      <td>Most web/store purchases</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Few Catalog purchases</td>\n",
    "      <td>Few Catalog purchases</td>\n",
    "      <td>Few Catalog purchases</td>\n",
    "      <td>Few Catalog purchases</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Few offers accepted</td>\n",
    "      <td>Few offers accepted</td>\n",
    "      <td>Few offers accepted</td>\n",
    "      <td>Most affers accepted</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{darkblue}{\\text{Products distribution}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataset \n",
    "clusters_products = data[['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'Cluster']]    # Select variables\n",
    "clusters_products = clusters_products.rename(columns={'MntWines':'Wines','MntFruits':'Fruits','MntMeatProducts':'Meat',\n",
    "'MntFishProducts':'Fish','MntSweetProducts':'Sweet','MntGoldProds':'Gold'})\n",
    "\n",
    "clusters_products1 = clusters_products.groupby(['Cluster'])\n",
    "clusters_products2 = clusters_products1.agg({'Wines':'sum', 'Fruits':'sum', 'Meat':'sum', 'Fish':'sum', 'Sweet':'sum', 'Gold':'sum'})\n",
    "\n",
    "clusters_products3 = clusters_products2.stack().reset_index(name='Count').rename(columns={'level_1':'Products'})   # Oposite as pivoting\n",
    "\n",
    "clusters_products3['group'] = clusters_products3['Cluster']\n",
    "clusters_products3['group'] = clusters_products3['group'].astype(str)\n",
    "\n",
    "# Rename values\n",
    "#clusters_products3['group'] = clusters_products3['group'].str.replace('0', 'Good Customers')\n",
    "#clusters_products3['group'] = clusters_products3['group'].str.replace('1', 'Elite Customers')\n",
    "#clusters_products3['group'] = clusters_products3['group'].str.replace('2', 'Economical Customers')\n",
    "#clusters_products3['group'] = clusters_products3['group'].str.replace('3', 'Cheap Customers')\n",
    "\n",
    "products = clusters_products3.copy()\n",
    "products = products.assign(ratio=products.groupby('group').Count.transform(lambda x: x / x.sum()))\n",
    "\n",
    "# Visualization\n",
    "fig = px.bar(products, x='group', y='ratio', color='Products',\n",
    "             labels={\n",
    "                     \"ratio\": \"Ratio\",\n",
    "                     \"group\": \"Consumer's type\"\n",
    "                     },\n",
    "             color_discrete_map={\n",
    "                     'Gold': '#FFD700',\n",
    "                     'Fish': '#87CEEB',\n",
    "                     'Wines': '#b11226',\n",
    "                     'Meat': '#f08080',\n",
    "                     'Sweet': '#FF69B4',\n",
    "                     'Fruits': 'lightgreen'},\n",
    "                title=\"Products Distribution by Clusters\")\n",
    "\n",
    "fig.layout.yaxis.tickformat = ',.0%'\n",
    "\n",
    "fig.update_traces(marker_line_color='white', marker_line_width=1, opacity=0.8)\n",
    "\n",
    "fig.update_xaxes(showgrid=False)\n",
    "fig.update_yaxes(showgrid=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    {'plot_bgcolor': 'black',\n",
    "    'paper_bgcolor': 'black'\n",
    "    },\n",
    "    font=dict(\n",
    "        family=\"verdana\",\n",
    "        size=21,\n",
    "        color=\"white\"\n",
    "    ),\n",
    "    width=680,\n",
    "    height=800,\n",
    "    title_font_color=\"#FFC300\",\n",
    "    yaxis_title=None,\n",
    "    xaxis_title=None\n",
    ")\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__\n",
    "\n",
    "1. Wine and meat are the most popular products amongst all the groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\color{darkblue}{\\text{7- General conclusion and recommendations}}$\n",
    "\n",
    "We used a dataset of 2240 customers described by 28 features.\n",
    "\n",
    "After some data analysis and cleaning, we used the PCA method to redure the features dimensions and some clustering methods to segment the customers into 4 clusters (recommended by Elbow method).\n",
    "\n",
    "We notice that in general, the more we earn the more we spend. The deals offered by the company are not widely used apart from the wealthy class. The majority of shopping is done either in store or online.\n",
    "We also note that wine and meat remain the most consumed products by all classes.\n",
    "\n",
    "To conclude this project, we'll offer some recommendations for the company based on our analysis:\n",
    "\n",
    "It would be beneficial to offer a greater variety of the most used products (Meat and wines) or special deals in these categories.\n",
    "\n",
    "The company can also offer more promotions for products (fish, fruits, ...) that are not sold well to encourage consumers to buy more.\n",
    "\n",
    "Most of the consumers have enrolled for a company membership for a long period of time. To promote and protect loyal clients, the company can offer some coupons to active, long-time customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
